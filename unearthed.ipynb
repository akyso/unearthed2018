
# coding: utf-8

# In[1]:


import pandas as pd
import numpy as np
from pathlib import Path
import pandas_profiling


# In[2]:


import matplotlib.pyplot as plt


# In[3]:


get_ipython().run_line_magic('matplotlib', 'inline')


# In[4]:


import altair as alt


# In[5]:


#alt.renderers.enable('notebook')
#alt.data_transformers.enable('default', max_rows=None)


# In[6]:


truck_cycle = Path('data')/"Truck Cycle.csv"


# In[7]:


parse_dates=['Date']
usecols= ['Date', 'Source bench', 'Truck', 'Travelling full duration', 'Payload', 'Full slope length',
         'Inpit Ramp length', 'Inpit Ramp Grade', 'Dump Ramp length', 'Dump Ramp Grade']
dtype= {'Date': 'object', 
        'Source bench': 'int', 
        'Truck': 'object', 
        'Travelling full duration': 'int', 
        'Payload': 'float', 
        'Full slope length': 'float',
        'Inpit Ramp length': 'float', 
        'Inpit Ramp Grade': 'object', 
        'Dump Ramp length': 'float', 
        'Dump Ramp Grade': 'object'}


# In[8]:


df_truck_cycle = pd.read_csv(truck_cycle, parse_dates=parse_dates, usecols=usecols)


# In[9]:


df_truck_cycle.head()


# In[10]:


df_truck_cycle['Inpit Ramp Grade'] = df_truck_cycle['Inpit Ramp Grade'].str.rstrip('%').astype('float') / 100.0
df_truck_cycle['Dump Ramp Grade'] = df_truck_cycle['Dump Ramp Grade'].str.rstrip('%').astype('float') / 100.0


# In[11]:


df_truck_cycle['Dump Ramp length'] = df_truck_cycle['Dump Ramp length'].str.strip()
df_truck_cycle.loc[df_truck_cycle['Dump Ramp length'] == '-', 'Dump Ramp length'] = np.nan


# In[12]:


df_truck_cycle['Full slope length'] = df_truck_cycle['Full slope length'].str.strip().str.replace(',', '').astype('float')
df_truck_cycle['Inpit Ramp length'] = df_truck_cycle['Inpit Ramp length'].str.strip().str.replace(',', '').astype('float')
df_truck_cycle['Dump Ramp length'] = df_truck_cycle['Dump Ramp length'].str.strip().str.replace(',', '').astype('float')


# In[13]:


df_truck_cycle.loc[df_truck_cycle['Dump Ramp length'].isnull(), 'Dump Ramp length'] = 0
df_truck_cycle.loc[df_truck_cycle['Dump Ramp length'] == 0, 'Dump Ramp Grade'] = 0


# In[14]:


df_truck_cycle['Truck'] = df_truck_cycle['Truck'].str.replace('TRH', '').astype('int')


# In[15]:


df_truck_cycle.dtypes


# In[16]:


df_truck_cycle.describe()


# In[17]:


#profile1 = pandas_profiling.ProfileReport(df_truck_cycle)
#profile1


# In[18]:


truck_spec = Path('data')/"Truck_Spec.csv"


# In[19]:


df_truck_spec = pd.read_csv(truck_spec, usecols=['Truck ID', 'Empty Weight (kg)'])


# In[20]:


df_truck_spec.head()


# In[21]:


df = df_truck_cycle.merge(df_truck_spec, how='left', left_on='Truck', right_on='Truck ID', copy=False)


# In[22]:


df.head()


# In[23]:


df["Empty Weight (kg)"] = df["Empty Weight (kg)"].astype('category')


# In[24]:


df.drop(['Truck', 'Truck ID'], axis=1, inplace=True)


# In[25]:


df.head()


# In[26]:


df['Source bench'].unique()


# ## Remove Outliers: Travelling full duration

# In[27]:


df.shape


# In[28]:


df = df[df['Travelling full duration'] > 0]


# In[29]:


df.shape


# ## Feature Engineering: Average Speed

# In[30]:


df['average_speed'] = df['Full slope length'] / df['Travelling full duration'] * 3.6


# ## Remove Outliers: Average Speed

# In[31]:


df = df[(df['average_speed'] >= 8) & (df['average_speed'] <= 34)]


# In[32]:


df.shape


# ## Remove Outliers: Payload

# In[33]:


df = df[(df['Payload'] > 100) & (df['Payload'] < 210)]


# In[34]:


df.shape


# ## Feature Engineering: Flat Length

# In[35]:


df['flat_length'] = df['Full slope length'] - (df['Inpit Ramp length'] + df['Dump Ramp length'])


# In[36]:


df = df[df['flat_length'] >= 0]


# In[37]:


df.shape


# In[38]:


profile2 = pandas_profiling.ProfileReport(df)
profile2


# In[39]:


df.to_csv('truck_merge.csv', index=False)


# In[40]:


from fastai.imports import *
from fastai.structured import *


# In[41]:


from sklearn.ensemble import RandomForestRegressor
from sklearn import metrics


# In[42]:


add_datepart(df, 'Date')


# In[43]:


df.dtypes


# In[44]:


df_trn, y_trn, nas = proc_df(df, 'Payload')


# In[45]:


x_train, y_train = df_trn, y_trn


# In[46]:


from sklearn.metrics import r2_score, mean_squared_error


# In[47]:


def print_score(m, x_train, y_train):
    y_pred = m.predict(x_train)
    res = {"R2 (train)": r2_score(y_train, y_pred), 
           "MSE (train)": mean_squared_error(y_train, y_pred)
          }
    for k, v in res.items():
        print(f'{k}: {v}')


# In[52]:


m = RandomForestRegressor(n_jobs=-1, random_state=888, n_estimators=50)
get_ipython().run_line_magic('time', 'm.fit(x_train, y_train)')


# In[53]:


print_score(m, x_train, y_train)


# In[56]:


fi = rf_feat_importance(m, df_trn)
fi[:50]


# In[54]:


def plot_fi(fi): return fi.plot('cols', 'imp', 'barh', figsize=(12,7), legend=False)


# In[57]:


plot_fi(fi[:20])


# In[60]:


from sklearn.preprocessing import StandardScaler

sc = StandardScaler()
x_train2 = sc.fit_transform(x_train)


# In[58]:


from sklearn.neural_network import MLPRegressor


# In[61]:


nn_model = MLPRegressor(solver='adam', alpha=1e-5, hidden_layer_sizes=(40, 20), random_state=1)


# In[62]:


nn_model.fit(x_train2, y_train)


# In[63]:


print_score(nn_model, x_train2, y_train)

